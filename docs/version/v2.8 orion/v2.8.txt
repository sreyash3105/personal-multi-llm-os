ğŸ· Version Name
V2.8 â€” Orion Stable Release

Reasoning:

V1 = First documented release

V2 = Pipeline + Dashboard + Vision + Chat era

V2.8 = Stable, feature-rich, before next major Tools runtime / Multi-agent upgrades

ğŸ“¦ V2.8 â€” ORION STABLE RELEASE (MASTER HANDOVER DOCUMENT)
ğŸ”° Overview

This version of Personal Local AI OS is a local-first offline Jarvis-style assistant running on a desktop server and operated from a laptop over LAN. It supports:

Multi-model code generation with escalation

Study & teaching mode

Vision for OCR / Debug / Screenshot interpretation

Multi-profile + multi-chat workspace

Local knowledge base per profile

Full dashboard trace

Rotating JSONL history

Configurable model roles

Git-ready project structure

This version is confirmed stable and runnable end-to-end.

ğŸ§  System Capabilities
Capability	Status
Code pipeline (coder â†’ judge â†’ reviewer â†’ escalation)	âœ” Stable
Study tutoring	âœ” Stable
Vision image processing	âœ” Stable
Dashboard & history	âœ” Stable
Multi-profile chat workspace	âœ” Stable
Profile knowledge base	âœ” Stable
Tools runtime	âŒ Not active in this version
Multi-agent	âŒ Not included
ğŸ—‚ Folder Structure (V2.8)
/server
 â”œâ”€ code_server.py      â† main FastAPI backend entrypoint
 â”œâ”€ config.py           â† model registry & global flags
 â”œâ”€ pipeline.py         â† coder / reviewer / judge / study
 â”œâ”€ vision_pipeline.py  â† vision model wrapper
 â”œâ”€ prompts.py          â† system prompts
 â”œâ”€ chat_ui.py          â† web-based chat page (HTML + JS)
 â”œâ”€ chat_storage.py     â† profiles + chats + messages (JSON)
 â”œâ”€ history.py          â† JSONL rotating logger
 â”œâ”€ dashboard.py        â† cognition trace visualizer
 â”œâ”€ static/chat.html    â† final rendered chat UI
 â”œâ”€ profile_kb.py       â† per-profile knowledge base
 â”œâ”€ legacy/             â† âœ” archived experimental modules
 â”œâ”€ .gitignore
 â”œâ”€ venv/
 â”œâ”€ history/
 â””â”€ models/ (optional if storing downloaded GGUF)

ğŸ”§ Configuration (config.py)

All Ollama model names stored in AVAILABLE_MODELS

Per-role selection:

Role	Default Model
Coder	qwen2.5-coder:7b
Reviewer	codestral:22b
Judge	qwen2.5:7b
Study	qwen2.5:14b
Chat	llama3:8b
Vision	llava:7b

Other toggles:

JUDGE_ENABLED = True
ESCALATION_ENABLED = True
VISION_ENABLED = True

ğŸ§© Core Modules
1ï¸âƒ£ Coding Engine

File: pipeline.py

Features:

Code-only enforcement

Reviewer safety net

Judge model scoring

Auto-escalation triggers when:

confidence < 8

conflict > 6

2ï¸âƒ£ Study Mode

Tags supported:

///short

///deep

///quiz

default = normal learning explanation

3ï¸âƒ£ Vision

File: vision_pipeline.py

Modes:

auto

describe

ocr

code

debug

4ï¸âƒ£ Chat Workspace

File: chat_ui.py

Profile selector

Multiple chats per profile

Fast response button + Smart response button

Auto scroll

Optional image upload (vision in chat)

Stores chats in JSON safely

5ï¸âƒ£ Dashboard

File: dashboard.py

Shows:

Mode

Prompt preview

Final output preview

Escalation

Confidence + Conflict scores

Judge summary

Full trace on click expand

ğŸ” Storage System
Component	Storage Method
chats	JSON (chat_storage.py)
KB notes	JSON (profile_kb.py)
history	JSONL (history/*.jsonl)

Future releases will optionally migrate to SQLite.

ğŸ§¾ Git Tracking

Included in repository:

All source modules

UI static files

Prompts

Config

Ignored:

venv/
models/
*.log
__pycache__/
history/

ğŸ“Œ Rollback / Failure Handling

Failures from experimental branches (Tools Runtime / New JS Parser) are archived inside:

/legacy/


Purpose:

preserve lessons

prevent accidental re-execution

allow controlled reintroduction in V3+

If needed, refer to Failure Report â€“ Tools Runtime upgrade (rollback).

ğŸ§­ Upgrade Roadmap From This Release
Next Step	Version Target
Tools system (LLM executable actions)	V3.0
Chat + Vision + Tools fusion	V3.2
Scheduler + background agents	V3.4
Multi-agent orchestrator	V4.0
ğŸŸ¢ Final Status of V2.8 â€” ORION STABLE RELEASE
Component	Status
Backend	ğŸŸ¢ Stable
Chat UI	ğŸŸ¢ Stable
Dashboard	ğŸŸ¢ Stable
Vision	ğŸŸ¢ Stable
Code + Study pipelines	ğŸŸ¢ Stable
KB	ğŸŸ¢ Stable
Tools runtime	âŒ Archived in legacy (not active)
ğŸ§© Deployment Command Reminder
cd D:\AI_Assistant\server
venv\Scripts\activate
uvicorn code_server:app --host 0.0.0.0 --port 8000 --reload


LAN access (laptop):

http://<PC-IP>:8000/chat
